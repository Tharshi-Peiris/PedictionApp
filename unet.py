# -*- coding: utf-8 -*-
"""UNet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AdTyKABe_l40ttxtJdqCSrR3vLuTegAk
"""

!pip install thop scikit-learn tqdm --quiet

import torch
import numpy as np
from tqdm import tqdm
from sklearn.metrics import f1_score
from thop import profile

# --------------------------
# Manual Metric Functions
# --------------------------

def pixel_accuracy(preds, labels):
    correct = (preds == labels).sum()
    total = torch.numel(labels)
    return correct / total

def mean_iou(preds, labels, num_classes=2):
    ious = []
    for cls in range(num_classes):
        pred_inds = preds == cls
        label_inds = labels == cls
        intersection = (pred_inds & label_inds).sum()
        union = (pred_inds | label_inds).sum()
        if union == 0:
            ious.append(float('nan'))
        else:
            ious.append((intersection / union).item())
    return np.nanmean(ious)

def dice_coefficient(preds, labels):
    preds = preds.flatten()
    labels = labels.flatten()
    intersection = (preds * labels).sum()
    return (2. * intersection) / (preds.sum() + labels.sum() + 1e-8)

def f1_score_binary(preds, labels):
    preds = preds.flatten()
    labels = labels.flatten()
    return f1_score(labels, preds, average='binary', zero_division=0)

# --------------------------
# Evaluation Loop
# --------------------------

model.eval()
total_acc = 0
total_iou = 0
total_dice = 0
total_f1 = 0
count = 0

with torch.no_grad():
    for images, masks in tqdm(val_loader, desc="Evaluating"):
        images = images.to(device)
        masks = masks.to(device)

        outputs = model(images)
        preds = torch.argmax(outputs, dim=1)

        acc = pixel_accuracy(preds.cpu(), masks.cpu())
        iou = mean_iou(preds.cpu(), masks.cpu())
        dice_score = dice_coefficient(preds.cpu().numpy(), masks.cpu().numpy())
        f1 = f1_score_binary(preds.cpu().numpy(), masks.cpu().numpy())

        total_acc += acc
        total_iou += iou
        total_dice += dice_score
        total_f1 += f1
        count += 1

# --------------------------
# Final Results
# --------------------------

print(f"\n✅ Evaluation Metrics:")
print(f"Pixel Accuracy:     {total_acc / count:.4f}")
print(f"Mean IoU:           {total_iou / count:.4f}")
print(f"Dice Coefficient:   {total_dice / count:.4f}")
print(f"F1 Score:           {total_f1 / count:.4f}")

# --------------------------
# FLOPs & Parameters
# --------------------------

dummy_input = torch.randn(1, 3, 256, 256).to(device)
macs, params = profile(model, inputs=(dummy_input,), verbose=False)

print(f"\n✅ Model Complexity:")
print(f"FLOPs (MACs):       {macs / 1e6:.2f} M")
print(f"Parameters:         {params / 1e6:.2f} M")

from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn.functional as F
from torchvision import transforms

# --------------------------
# Load Model
# --------------------------
model = UNet(in_channels=3, out_channels=2)  # match architecture
model.load_state_dict(torch.load("/content/unet_segmentation.pth", map_location=device))
model = model.to(device)
model.eval()

# --------------------------
# Load and Preprocess Image
# --------------------------
# Upload an image in Colab manually or use any path
from google.colab import files
uploaded = files.upload()

# Get uploaded filename
img_path = list(uploaded.keys())[0]

# Load and preprocess
test_image = Image.open(img_path).convert("RGB").resize((256, 256))
transform = transforms.Compose([transforms.ToTensor()])
input_tensor = transform(test_image).unsqueeze(0).to(device)  # [1, 3, 256, 256]

# --------------------------
# Predict
# --------------------------
with torch.no_grad():
    output = model(input_tensor)                     # [1, 2, 256, 256]
    pred_mask = torch.argmax(output.squeeze(), dim=0).cpu().numpy()  # [256, 256]

# --------------------------
# Overlay Prediction
# --------------------------
original = np.array(test_image.resize((256, 256)))

# Create red mask overlay
colored_mask = np.zeros_like(original)
colored_mask[:, :, 0] = 255  # Red
colored_mask[:, :, 1] = 100  # Green
colored_mask[:, :, 2] = 100  # Blue

alpha = 0.4
mask_3d = np.stack([pred_mask]*3, axis=-1)

# Blend original + mask
overlayed = np.where(mask_3d == 1,
                     (alpha * colored_mask + (1 - alpha) * original).astype(np.uint8),
                     original)

# --------------------------
# Show Results
# --------------------------
plt.figure(figsize=(12, 6))
plt.subplot(1, 3, 1)
plt.imshow(original)
plt.title("Original Image")

plt.subplot(1, 3, 2)
plt.imshow(pred_mask, cmap='gray')
plt.title("Predicted Mask")

plt.subplot(1, 3, 3)
plt.imshow(overlayed)
plt.title("Overlayed Prediction")
plt.axis("off")
plt.show()